---
title: "Synthesizing by means of mice"
author:
- Thom Volker
- Utrecht University
date: "`r format(Sys.time(), '%d-%m-%Y')`"
output: 
  html_document:
    theme: spacelab
    highlight: tango
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: true
bibliography: federated_imp.bib
csl: "/Users/thomvolker/Documents/styles/apa-6th-edition.csl"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
thomcache <- TRUE; thomlazy <- FALSE #obviously ;)
library(tidyverse)
```

# Use mice to impute all data

```{r, include = F, cache = thomcache, cache.lazy=thomlazy}
source("1.a Synthesize_Mice_Replace_All.R")
```

First, we again create 1 complete dataset, which is done by means of imputing the `boys` dataset in `mice` [@mice] with default settings, and complete the dataset. Then, based on this one true dataset, we extract the regression coefficients of a linear regression model in which weight is regressed on age and height, that are used to compare the estimates of the synthetic versions of the datasets. The true regression coefficients are equal to $\beta_0 = `r round(coefs[1],3)`$, $\beta_{age} = `r round(coefs[2], 3)`$, $\beta_{height} = `r round(coefs[3], 3)`$. Then, for a total of 200 iterations, we impute a matrix with the same dimensions as the boys dataset (that is, the sample size $n = `r nrow(truth)`$ and the number of predictors $k = `r ncol(truth)`$). This is done once with the default settings, that is, with `pmm` for the continuous variables, `polr` for binary variables and `polyreg` for ordinal variables with more than two categories. Furthermore, `bmi` is imputed passively, since it consists of a fixed combination of height and weight `bmi = (wgt / (hgt/100)^2`. Furthermore, the predictor matrix is adjusted so that imputations for `bmi` do not flow back into predictions of `hgt` and `wgt`. Then, for every synthetic dataset, the estimates, and corresponding variance of the estimates are calculated, as well as the $95\%~CI$ are calculated. Furthermore, an indicator is added, whether or not the confidence interval includes the true parameter estimates. Note that these confidence intervals are still based on imputations for missing data, instead of imputations for synthetic data. This is due to the fact that the calculation for the degrees of freedom for the estimates based imputing synthetic values might yield degrees of freedom that are so small that the corresponding $95\% ~ CI$ yields boundary values of $-\infty$ and $\infty$. 

## True results
```{r, echo = F}
broom::tidy(truemodel, conf.int=TRUE) %>%
  mutate(CIW = conf.high - conf.low) %>% knitr::kable(digits = 3)
```

## Impute all values

```{r, echo = F}
bind_rows("Mice default" = results_def,
          "Mice with cart" = results_cart, .id = "Imputation method") %>% knitr::kable(digits = 3)
```

## Impute part of the values

Additionally, an approach is tested in which $\frac{5}{9}$ of the values are randomly selected to be imputed. Using this approach, eventually in two steps, all values can be replaced, while still using almost 50% of the information that is already in the data. Eventually, in a second step, the other almost 50% can be replaced, and the datafiles can be merged so that eventually the full dataset can be made synthetic again. However, currently this is not yet implemented.

```{r, echo = F}
bind_rows("Mice default" = results_def_50,
          "Mice with cart" = results_cart_50, .id = "Imputation method") %>% knitr::kable(digits = 3)
```


```{r, include = F, cache = thomcache}
future::plan(future::multisession)
all_syns_wgt_hgt <- future_map(1:nsim, ~ {
  truth %>% mice(m = 5, 
                 method = cart,
                 visitSequence = c("age", "wgt", "hgt", "bmi", "hc", "gen", "phb", "tv", "reg"),
                 predictorMatrix = pred,
                 where = matrix(TRUE, nrow(truth), ncol(truth)),
                 print = F)
}, .options = future_options(seed = as.integer(123)), .progress = TRUE, .id = "syn")
```


## Different visiting sequence


```{r, echo = F}
est_wgt_hgt <- all_syns_wgt_hgt %>% map(function(x) with(x, lm(wgt ~ age + hgt)) %>% pool %>% summary)

CIs_wgt_hgt <- map(est_wgt_hgt, function(x) {
  
  var      <- x[,1]
  true_est <- coefs
  est      <- x[,2]
  true_se  <- sqrt(diag(vcov(truemodel)))
  se       <- x[,3]
  lower    <- x[,2] + x[,3] * qt(.025, x[,5])
  upper    <- x[,2] + x[,3] * qt(.975, x[,5])
  cov      <- lower < coefs & coefs < upper
  
  bind_cols(var = var, true_est = true_est, est = est, true_se = true_se, se = se, lower = lower, upper = upper, cov = cov)
})

results_wgt_hgt <- CIs_wgt_hgt %>% bind_rows %>% group_by(var) %>%
  summarise("True Est" = unique(true_est),
            "Syn Est"  = mean(est),
            "Bias"     = mean(est - true_est),
            "True SE"  = unique(true_se),
            "Syn SE"   = mean(se),
            "CIW"      = mean(upper - lower),
            "Coverage" = mean(cov))

```
# References

